{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quantitative-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 该包提供类似关系型数据库（Oracle）中以表格形式处理数据的功能，更加灵活\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import cv2\n",
    "import os\n",
    "from collections import Counter\n",
    "#tqdm是一个快速，可扩展的Python进度条，可以在 Python 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器\n",
    "from tqdm import tqdm\n",
    "# ----------------部分参数设置----------------------\n",
    "# 训练数据集地址\n",
    "train_img_url = '/data0/1'\n",
    "# 将所有的图片resize成512*512\n",
    "w = 512\n",
    "h = 512\n",
    "c = 3\n",
    "learning_rate=0.0001\n",
    "# GPU内存限制数\n",
    "#gpu_memory = 5120\n",
    "# 每次执行图片数\n",
    "batch_size = 3\n",
    "# 网络fit迭代次数\n",
    "num_epochs = 100\n",
    "#-------------------设置显存占用率-----------------\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# 对需要进行限制的GPU进行设置\n",
    "#tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=gpu_memory)])\n",
    "# 查看GPU是否可用\n",
    "#print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "integrated-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85\n",
       "1    75\n",
       "3    46\n",
       "2    40\n",
       "5    30\n",
       "6    21\n",
       "4    18\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './rock_label.csv'\n",
    "# 读取类标数据\n",
    "data_df = pd.read_csv(data_path,encoding='gbk')\n",
    "# 对label进行Encoder编码\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_data = pd.DataFrame(columns=['label'])\n",
    "le_credit_level = LabelEncoder().fit(data_df['样本类别'])\n",
    "label_data['label'] = le_credit_level.transform(data_df['样本类别'])\n",
    "label_counts = len(list(label_data['label'].value_counts()))\n",
    "label_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "delayed-vietnam",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/315 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集地址：/data0/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [02:47<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "#图片加载\n",
    "# 读取图片+数据处理函数\n",
    "def read_img(path,label_pd):\n",
    "    print(\"数据集地址：\"+path)\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in tqdm(files):\n",
    "            # print(path+'/'+file+'/'+folder)\n",
    "            # 读取的图片\n",
    "            # img = io.imread(os.path.join(root,file))\n",
    "            img = cv2.imread(os.path.join(root, file))\n",
    "            # skimage.transform.resize(image, output_shape)改变图片的尺寸\n",
    "            img = cv2.resize(img, (w, h))\n",
    "            # 将读取的图片数据加载到imgs[]列表中\n",
    "            imgs.append(img)\n",
    "    labels = list(label_pd['label'])\n",
    "    # 将读取的图片和labels信息，转化为numpy结构的ndarr(N维数组对象（矩阵）)数据信息\n",
    "    return imgs,labels\n",
    "# 调用读取图片的函数，得到图片和labels的数据集\n",
    "data1, label1 = read_img(train_img_url,label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eleven-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:06<00:00, 49.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# 将图像进行随机翻转，裁剪\n",
    "def img_cut(imgs,label):\n",
    "    imgs_out = []\n",
    "    label_out = []\n",
    "    for i in tqdm(range(len(imgs))):\n",
    "        # 添加原图\n",
    "        imgs_out.append(imgs[i])\n",
    "        label_out.append(label[i])\n",
    "        # 随机翻转\n",
    "        for e in range(-1,2):\n",
    "            # 1:水平翻转,0:垂直翻转,-1:水平垂直翻转\n",
    "            f_img = cv2.flip(imgs[i], e)\n",
    "            # 添加翻转图像\n",
    "            imgs_out.append(f_img)\n",
    "            # 添加类标\n",
    "            label_out.append(label[i])\n",
    "            # 裁剪翻转后图片\n",
    "            # 生成裁剪随机数：70%-90%大小\n",
    "            rd_num = np.random.uniform(0.7, 0.9)\n",
    "            # 生成随机裁剪长宽\n",
    "            rd_w = int(w * rd_num)\n",
    "            rd_h = int(h * rd_num)\n",
    "            # 进行裁剪\n",
    "            crop_img = tf.image.random_crop(imgs[i],[rd_w,rd_h,c]).numpy()\n",
    "            # 重新调整大小\n",
    "            re_img = cv2.resize(crop_img, (w, h))\n",
    "            # 添加裁剪图像\n",
    "            imgs_out.append(re_img)\n",
    "            # 添加类标\n",
    "            label_out.append(label[i])\n",
    "        # 原图随机裁剪，执行3次\n",
    "        for f in range(3):\n",
    "            # 生成裁剪随机数：50%-80%大小\n",
    "            rd_num = np.random.uniform(0.5, 0.8)\n",
    "            # 生成随机裁剪长宽\n",
    "            rd_w = int(w * rd_num)\n",
    "            rd_h = int(h * rd_num)\n",
    "            # 进行裁剪\n",
    "            crop_img = tf.image.random_crop(imgs[i],[rd_w,rd_h,c]).numpy()\n",
    "            # 重新调整大小\n",
    "            re_img = cv2.resize(crop_img, (w, h))\n",
    "            # 添加裁剪图像\n",
    "            imgs_out.append(re_img)\n",
    "            # 添加类标\n",
    "            label_out.append(label[i])\n",
    "    return imgs_out,label_out\n",
    "# 执行函数\n",
    "data2,label2 = img_cut(data1,label1)\n",
    "# 将图像数据转换为numpy数组\n",
    "data_sample,label_sample = np.asarray(data2, np.float32), np.asarray(label2, np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "seven-slovak",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150, 512, 512, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "genuine-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 750, 6: 210, 4: 180, 0: 850, 2: 400, 5: 300, 3: 460})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mineral-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱顺序\n",
    "# 读取data矩阵的第一维数（图片的个数）\n",
    "num_example = data_sample.shape[0]\n",
    "# 产生一个num_example范围，步长为1的序列\n",
    "arr = np.arange(num_example)\n",
    "# 调用函数，打乱顺序\n",
    "np.random.shuffle(arr)\n",
    "# 按照打乱的顺序，重新排序\n",
    "data= data_sample[arr]\n",
    "label= label_sample[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bound-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#恒等模块——identity_block\n",
    "def identity_block(X,f,filters,stage,block):\n",
    "    \"\"\"\n",
    "    三层的恒等残差块\n",
    "    param :\n",
    "        X -- 输入的张量，维度为（m, n_H_prev, n_W_prev, n_C_prev）\n",
    "        f -- 整数，指定主路径的中间 CONV 窗口的形状\n",
    "        filters -- python整数列表，定义主路径的CONV层中的过滤器数目\n",
    "        stage -- 整数，用于命名层，取决于它们在网络中的位置\n",
    "        block --字符串/字符，用于命名层，取决于它们在网络中的位置    \n",
    "    return:    \n",
    "        X -- 三层的恒等残差块的输出，维度为：(n_H, n_W, n_C)    \n",
    "    \"\"\"\n",
    "    #定义基本的名字\n",
    "    conv_name_base = \"res\"+str(stage)+block+\"_branch\"\n",
    "    bn_name_base = \"bn\"+str(stage)+block+\"_branch\"\n",
    "    #过滤器\n",
    "    F1,F2,F3=filters\n",
    "    #保存输入值，后将输入值返回主路径\n",
    "    X_shortcut = X\n",
    "    \n",
    "    #主路径第一部分\n",
    "    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\",kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    \n",
    "    #主路径第二部分\n",
    "    X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=\"same\",\n",
    "               name=conv_name_base+\"2b\",kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    \n",
    "    #主路径第三部分\n",
    "    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\",kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "\n",
    "    # 主路径最后部分,为主路径添加shortcut并通过relu激活\n",
    "    X = layers.Add()([X,X_shortcut])\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incident-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#卷积残差块——convolutional_block\n",
    "def convolutional_block(X,f,filters,stage,block,s=2):\n",
    "    \"\"\"    \n",
    "    param :\n",
    "    X -- 输入的张量，维度为（m, n_H_prev, n_W_prev, n_C_prev）\n",
    "    f -- 整数，指定主路径的中间 CONV 窗口的形状（过滤器大小，ResNet中f=3）\n",
    "    filters -- python整数列表，定义主路径的CONV层中过滤器的数目\n",
    "    stage -- 整数，用于命名层，取决于它们在网络中的位置\n",
    "    block --字符串/字符，用于命名层，取决于它们在网络中的位置\n",
    "    s -- 整数，指定使用的步幅\n",
    "    return:\n",
    "    X -- 卷积残差块的输出，维度为：(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    #定义基本名字\n",
    "    conv_name_base = \"res\"+str(stage)+block+\"_branch\"\n",
    "    bn_name_base = \"bn\"+str(stage)+block+\"_branch\"\n",
    "    #过滤器\n",
    "    F1,F2,F3=filters\n",
    "    #保存输入值，后将输入值返回主路径\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # 主路径第一部分\n",
    "    X = layers.Conv2D(filters=F1, kernel_size=(1, 1), strides=(s,s), padding=\"valid\",\n",
    "               name=conv_name_base + \"2a\", kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3, name=bn_name_base + \"2a\")(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    \n",
    "    # 主路径第二部分\n",
    "    X = layers.Conv2D(filters=F2, kernel_size=(f, f), strides=(1,1), padding=\"same\",\n",
    "               name=conv_name_base + \"2b\", kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3, name=bn_name_base + \"2b\")(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    \n",
    "    # 主路径第三部分\n",
    "    X = layers.Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding=\"valid\",\n",
    "               name=conv_name_base + \"2c\", kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3, name=bn_name_base + \"2c\")(X)\n",
    "    \n",
    "    #shortcut路径\n",
    "    X_shortcut = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding=\"valid\",\n",
    "                        name=conv_name_base+\"1\",kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = layers.BatchNormalization(axis=3,name=bn_name_base+\"1\")(X_shortcut)\n",
    "\n",
    "    # 主路径最后部分,为主路径添加shortcut并通过relu激活\n",
    "    X = layers.Add()([X, X_shortcut])\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "identified-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "#50层ResNet模型构建\n",
    "def ResNet50(input_shape = (w,h,c),classes = label_counts):\n",
    "    \"\"\" \n",
    "    构建50层的ResNet,结构为：\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "    \n",
    "    param : \n",
    "        input_shape -- 数据集图片的维度\n",
    "        classes -- 整数，分类的数目\n",
    "    return:\n",
    "        model -- Keras中的模型实例\n",
    "    \"\"\"\n",
    "    #将输入定义为维度大小为 input_shape的张量\n",
    "    X_input = layers.Input(input_shape)\n",
    "    # Zero-Padding\n",
    "    X = layers.ZeroPadding2D((3,3))(X_input)\n",
    "    # Stage 1\n",
    "    X = layers.Conv2D(64,kernel_size=(7,7),strides=(2,2),name=\"conv1\",kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    X = layers.BatchNormalization(axis=3,name=\"bn_conv1\")(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    X = layers.MaxPooling2D(pool_size=(3,3),strides=(2,2))(X)\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X,f=3,filters=[64,64,256],stage=2,block=\"a\",s=1)\n",
    "    X = identity_block(X,f=3,filters=[64,64,256],stage=2,block=\"b\")\n",
    "    X = identity_block(X,f=3,filters=[64,64,256],stage=2,block=\"c\")\n",
    "    #Stage 3\n",
    "    X = convolutional_block(X,f=3,filters=[128,128,512],stage=3,block=\"a\",s=2)\n",
    "    for i in range(7):\n",
    "        X = identity_block(X,f=3,filters=[128,128,512],stage=3,block=\"b\"+str(i))\n",
    "    # Stage 4 \n",
    "    X = convolutional_block(X,f=3,filters=[256,256,1024],stage=4,block=\"a\",s=2)\n",
    "    for i in range(35):\n",
    "        X = identity_block(X,f=3,filters=[256,256,1024],stage=4,block=\"b\"+str(i))\n",
    "    #Stage 5 \n",
    "    X = convolutional_block(X,f=3,filters=[512,512,2048],stage=5,block=\"a\",s=2)\n",
    "    X = identity_block(X,f=3,filters=[256,256,2048],stage=5,block=\"b\")\n",
    "    X = identity_block(X,f=3,filters=[256,256,2048],stage=5,block=\"c\")\n",
    "    #最后阶段\n",
    "    #平均池化 \n",
    "    X = layers.AveragePooling2D(pool_size=(2,2))(X)\n",
    "    #输出层\n",
    "    X = layers.Flatten()(X)\n",
    "    #展平\n",
    "    X = layers.Dense(classes,activation=\"softmax\",name=\"fc\"+str(classes),kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "    #创建模型\n",
    "    model = keras.models.Model(inputs=X_input,outputs=X,name=\"ResNet50\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "herbal-buying",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e7a6e6a1192a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#运行构建的模型图\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mResNet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#编译模型来配置学习过程\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ResNet_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n\u001b[1;32m      5\u001b[0m                      \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ResNet50' is not defined"
     ]
    }
   ],
   "source": [
    "#运行构建的模型图\n",
    "ResNet_model = ResNet50(input_shape=(w,h,c),classes=label_counts)\n",
    "#编译模型来配置学习过程\n",
    "ResNet_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "'''\n",
    "第一轮训练100个epoch\n",
    "'''\n",
    "history_1 = ResNet_model.fit(data,label, epochs = num_epochs,batch_size = batch_size,validation_split=0.1)\n",
    "#保存模型\n",
    "ResNet_model.save('models_save/Resnet_model_0504_100.h5')\n",
    "'''\n",
    "第二轮训练100个epoch\n",
    "'''\n",
    "history_2 = ResNet_model.fit(data,label, epochs = num_epochs,batch_size = batch_size,validation_split=0.1)\n",
    "#保存模型\n",
    "ResNet_model.save('models_save/Resnet_model_0504_200.h5')\n",
    "'''\n",
    "第三轮训练100个epoch\n",
    "'''\n",
    "history_3 = ResNet_model.fit(data,label, epochs = num_epochs,batch_size = batch_size,validation_split=0.1)\n",
    "#保存模型\n",
    "ResNet_model.save('models_save/Resnet_model_0504_300.h5')\n",
    "'''\n",
    "第四轮训练100个epoch\n",
    "'''\n",
    "history_4 = ResNet_model.fit(data,label, epochs = num_epochs,batch_size = batch_size,validation_split=0.1)\n",
    "#保存模型\n",
    "ResNet_model.save('models_save/Resnet_model_0504_400.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-chick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
