{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bibliographic-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import unet\n",
    "from glob import glob\n",
    "import torch\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from skimage.io import imread, imsave\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chinese-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = joblib.load('models/jiu0Monkey_Unet_woDS/args.pkl')\n",
    "\n",
    "joblib.dump(args, 'models/jiu0Monkey_Unet_woDS/args.pkl')\n",
    "model = unet.__dict__[args.arch](args)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cognitive-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 160, 160)\n",
      "(1, 4, 160, 160)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (down1): Downsample_block(\n",
       "    (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (down2): Downsample_block(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (down3): Downsample_block(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (down4): Downsample_block(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (up4): Upsample_block(\n",
       "    (transconv): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (up3): Upsample_block(\n",
       "    (transconv): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (up2): Upsample_block(\n",
       "    (transconv): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (up1): Upsample_block(\n",
       "    (transconv): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (outconv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (outconvp1): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (outconvm1): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = np.load('/data0/BraTS2020/testImage/BraTS20_Validation_113_88.npy')\n",
    "data1 = data1.T\n",
    "print(data1.shape)\n",
    "data1 = np.expand_dims(data1,0)\n",
    "#data1.reshape()\n",
    "print(data1.shape)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "img_ = torch.from_numpy(data1).type(torch.FloatTensor) \n",
    "img = img_.to(device=device, dtype=torch.float32)\n",
    "model.load_state_dict(torch.load('models/jiu0Monkey_Unet_woDS/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "understanding-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset = Dataset(args,val_img_paths)\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#         val_dataset,\n",
    "#         batch_size=args.batch_size,\n",
    "#         shuffle=False,\n",
    "#         pin_memory=True,\n",
    "#         drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empirical-brother",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 160, 160)\n"
     ]
    }
   ],
   "source": [
    " with torch.no_grad():\n",
    "    img = img.cuda()\n",
    "    output = model(img)\n",
    "    #print(\"img_paths[i]:%s\" % img_paths[i])\n",
    "    output = torch.sigmoid(output).data.cpu().numpy()\n",
    "    print(output.shape)\n",
    "    np.save('test.npy',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wicked-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with warnings.catch_warnings():\n",
    "#             warnings.simplefilter('ignore')\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 for i, (input) in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "#                     input = input.cuda()\n",
    "#                     #target = target.cuda()\n",
    "\n",
    "#                     # compute output\n",
    "#                     if args.deepsupervision:\n",
    "#                         output = model(input)[-1]\n",
    "#                     else:\n",
    "#                         output = model(input)\n",
    "#                     #print(\"img_paths[i]:%s\" % img_paths[i])\n",
    "#                     output = torch.sigmoid(output).data.cpu().numpy()\n",
    "#                     img_paths = val_img_paths[args.batch_size*i:args.batch_size*(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lesser-crisis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(output.shape[0]):\n",
    "    \"\"\"\n",
    "    生成灰色圖片\n",
    "    wtName = os.path.basename(img_paths[i])\n",
    "    overNum = wtName.find(\".npy\")\n",
    "    wtName = wtName[0:overNum]\n",
    "    wtName = wtName + \"_WT\" + \".png\"\n",
    "    imsave('output/%s/'%args.name + wtName, (output[i,0,:,:]*255).astype('uint8'))\n",
    "    tcName = os.path.basename(img_paths[i])\n",
    "    overNum = tcName.find(\".npy\")\n",
    "    tcName = tcName[0:overNum]\n",
    "    tcName = tcName + \"_TC\" + \".png\"\n",
    "    imsave('output/%s/'%args.name + tcName, (output[i,1,:,:]*255).astype('uint8'))\n",
    "    etName = os.path.basename(img_paths[i])\n",
    "    overNum = etName.find(\".npy\")\n",
    "    etName = etName[0:overNum]\n",
    "    etName = etName + \"_ET\" + \".png\"\n",
    "    imsave('output/%s/'%args.name + etName, (output[i,2,:,:]*255).astype('uint8'))\n",
    "    \"\"\"\n",
    "    rgbPic = np.zeros([160, 160, 3], dtype=np.uint8)\n",
    "    for idx in range(output.shape[2]):\n",
    "        for idy in range(output.shape[3]):\n",
    "            if output[i,0,idx,idy] > 0.5:\n",
    "                rgbPic[idx, idy, 0] = 0\n",
    "                rgbPic[idx, idy, 1] = 128\n",
    "                rgbPic[idx, idy, 2] = 0\n",
    "            if output[i,1,idx,idy] > 0.5:\n",
    "                rgbPic[idx, idy, 0] = 255\n",
    "                rgbPic[idx, idy, 1] = 0\n",
    "                rgbPic[idx, idy, 2] = 0\n",
    "            if output[i,2,idx,idy] > 0.5:\n",
    "                rgbPic[idx, idy, 0] = 255\n",
    "                rgbPic[idx, idy, 1] = 255\n",
    "                rgbPic[idx, idy, 2] = 0\n",
    "    rgbPic = np.array(rgbPic)\n",
    "    print(rgbPic.shape)\n",
    "    for i in range(3):\n",
    "        rgbPic[:,:,i]=rgbPic[:,:,i].T\n",
    "    imsave('test1.png',rgbPic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-horizon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-lemon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
